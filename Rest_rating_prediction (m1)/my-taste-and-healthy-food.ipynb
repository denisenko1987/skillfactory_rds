{"cells":[{"metadata":{"trusted":true},"cell_type":"markdown","source":"#Предсказание рейтинга ресторана по версии TripAdvisor\nСобственно это каггловское соревнование со следующими вводными:\n\nВ этом соревновании вам будет предложен датасет, содержащий сведения о ресторанах. С помощью имеющего в вашем распоряжении кода, вам необходимо создать модель, использующую алгоритм RandomForestRegression, которая будет прогнозировать рейтинг ресторана по версии TripAdvidor.\n\nОсновная цель: качественно очистить датасет, подобрать подходящие значения для заполнения пропусков и создать новые признаки на основе той информации, которую вы сможете извлечь из имеющихся в вашем распоряжении данных.\n\nУсловия соревнования: Все участники должны использовать один и тот же алгоритм с параметрами, заданными по умолчанию. Разрешено использовать внешние данные."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# при загрузке использую расширение .xls, так как при сохранении файлов на компьютер, они автоматически сохраняются\n# в том формате.\nDATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# А теперь неожиданно!!! - помечаем датафреймы и объединяем в один (предварительно создав колонку Rating в df_test)\ndf_train['sample'] = 1 \ndf_test['sample'] = 0 \ndf_test['Rating'] = 0 \n\ndf = df_test.append(df_train, sort=False).reset_index(drop=True)\n\ndffin = pd.DataFrame()\ndffin['Restaurant_id'] = df['Restaurant_id']\n\n#df = df.drop(['Name'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим, что получилось\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ПЕРВЫМ ДЕЛОМ РАЗБЕРЕМСЯ С ПРОПУСКАМИ В ДАННЫХ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Чтобы заполнить недостающие данные в столбце Cuisine Stile, самые популярные виды кухонь в каждом городе\n# сделаем датафрейм с городами и самыми популярными там кухнями\ndf2 = df.dropna(subset=['Cuisine Style'], inplace=False)\ndf2 = df2.groupby('City')['Cuisine Style'].sum().apply(lambda x:x.replace('[','').replace(']','').replace('\\'','').split(', '))\n\n# Так как среднее количество кухонь на 1 ресторан = 2.6, то найдем три самые популярные кухни для каждого города\nmostpop=[]\nfor i in range(len(df2)):\n    pop = []\n    trt = pd.Series(df2[i]).value_counts() # нашли самые популярные кухни\n    pop.append(pd.DataFrame(trt).index[0])\n    pop.append(pd.DataFrame(trt).index[1])\n    pop.append(pd.DataFrame(trt).index[2])\n    mostpop.append(pop) # сунули их в список\n\nmostpop = pd.Series(mostpop)\n\ncit = pd.DataFrame(df2.index)\n\ncit_cus = pd.concat([cit,mostpop], axis=1)\ncit_cus.columns = ['City', 'Most pop cuisine']\ncit_cus['Capital'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Че получилось:\ncit_cus.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Очистим столбец Cuisine Stile и переведем их в список\ndf['Cuisine Style'] = df['Cuisine Style'].loc[df['Cuisine Style'].isna() == False].apply(lambda x:x.replace('[','').replace(']','').replace('\\'','').split(', '))\n\n# Соединим две таблицы\ndf = df.merge(cit_cus, on='City', how = 'left')\n\n# Заполним nan-ы из Cuisine Style данными из Most pop cuisine\ndf['Cuisine Style'] = df['Cuisine Style'].fillna(df['Most pop cuisine'])\n\n# Ну и удалим 'Most pop cuisine'\ndf = df.drop(['Most pop cuisine'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Теперь колонка Cuisine Style заполнена"},{"metadata":{"trusted":true},"cell_type":"code","source":"# запилим список со столицами государств\ncapitals = ['London', 'Paris', 'Madrid', 'Berlin', 'Rome', 'Prague', 'Lisbon', 'Vienna', 'Amsterdam', 'Brussels', \n            'Stockholm', 'Budapest', 'Warsaw', 'Dublin', 'Copenhagen', 'Athens', 'Edinburgh', 'Oslo', 'Helsinki', \n            'Bratislava', 'Luxembourg', 'Ljubljana']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# отметим в датафрейме столицы - 1, остальные города - 0\ndf['Capital'].loc[df['City'].isin(capitals)] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Теперь разберемся с колонкой Price"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Price Range'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Первым делом переведем существующие занчения в числовые аналоги\n# Для того запилим датафрейм\ndfprice = pd.DataFrame({'Price Range': ['$', '$$ - $$$', \n                                        '$$$$'], 'Price New': [1,2, 3]})\ndf = df.merge(dfprice, on='Price Range', how = 'left')\n\n# И удалим столбец 'Price Range', чтоб он нас более не смущал\ndf = df.drop(['Price Range'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Price New'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Найдем для каждого города наиболее верояную ценовую политику ресторанов"},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_city_price={}\n\nfor city in df['City'].unique():\n    price = df[df['City']==city]['Price New'].value_counts().index[0]\n    dict_city_price[city]=price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_city_price","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Как видим, для всех городов наиболее частая ценовая категория - 2. Поэтому просто заполним пропуски в данных двойкой"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Price New'] = df['Price New'].fillna(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Найдем, колько дней прошло с момента последнего отзыва\n\nimport re\n\ndf['Reviews'] = df['Reviews'].apply(lambda x: str([[], []]) if type(x) == float else x) \ndf['Reviews'] = df['Reviews'].apply(lambda x: str(x) if type(x) == list else x)\n\n# Вытащим даты отзывов из столбца\nres = []\nfor i in df['Reviews']:\n    res.append(re.findall(r'(\\d\\d/\\d\\d/\\d\\d\\d\\d)', i))\nreviews = pd.DataFrame(res)\nreviews[0] = pd.to_datetime(reviews[0])\nreviews[1] = pd.to_datetime(reviews[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport datetime as dt\nfrom datetime import date, timedelta\n\ntoday = pd.to_datetime(date.today().strftime('%Y-%m-%d'))\n\nfromtoday = []\n\n# Как видим, в столбце 0 даты более поздние, поэтому будем искать разницу именно с ними\nfor i in range(len(reviews)):\n    fromtoday.append(today - reviews.loc[i, 0])\n\n# Создадим столбец под эти бесценные данные    \ndf['fromtoday'] = pd.Series(fromtoday)\ndf['fromtoday'] = df['fromtoday'].apply(lambda x: x.days if (type(x) != int) else 0)\ndf['fromtoday'] = df['fromtoday'].fillna(0)\n\n# И, раз пошла такая пьянка, найдем разницу между двумя отзывами\n\ndf['delta_days'] = reviews[0] - reviews[1]\ndf['delta_days'] = df['delta_days'].apply(lambda x: x.days if type(x) != float else 0)\ndf['delta_days'] = df['delta_days'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сделаем столбец под id ресторана\n\ndf['id'] = df['Restaurant_id'].apply(lambda x: int(x[3:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавим некоторые экономические показатели для каждого города\n\nGDP = {'London': 41030, 'Paris': 41760, 'Madrid': 29961, 'Barcelona': 29961, 'Berlin': 46563, 'Milan': 32946,\n       'Rome': 32946, 'Prague': 23213, 'Lisbon': 23030, 'Vienna': 50022, 'Amsterdam': 52367, 'Brussels': 45175, \n       'Hamburg': 46563, 'Munich': 46563, 'Lyon': 41760, 'Stockholm': 51241, 'Budapest': 17463, 'Warsaw': 14901,\n       'Dublin': 77771, 'Copenhagen': 59795, 'Athens': 19974, 'Edinburgh': 42500, 'Zurich': 83716, 'Oporto': 23030,\n       'Geneva': 83716, 'Krakow': 14901, 'Oslo': 77957, 'Helsinki': 48868, 'Bratislava': 19547, 'Luxembourg': 113196,\n       'Ljubljana': 26170}\n\n\nCityPop = {'Paris':2140526, 'Stockholm': 1632798, 'London': 9126366, 'Berlin':3748148, 'Munich':1456039, 'Oporto': 2400000,\n       'Milan':1405879, 'Bratislava':434926, 'Vienna':1899055, 'Rome':2857321, 'Barcelona':1620343, 'Madrid':3223334,\n       'Dublin':1361000, 'Brussels':1211035, 'Zurich':1383000, 'Warsaw':1802237, 'Budapest':1749734, 'Copenhagen':1334000,\n       'Amsterdam':1140000, 'Lyon':513275, 'Hamburg':1930996, 'Lisbon':2927000, 'Prague':1308632, 'Oslo':1041377,\n       'Helsinki':1304851, 'Edinburgh':531000, 'Geneva':201741, 'Ljubljana':292988, 'Athens':3154000,\n       'Luxembourg':613894, 'Krakow':762508}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Делаем колонку GDP\ndfGDP = pd.Series(GDP).reset_index()\ndfGDP.columns = ['City', 'GDP']\ndf = df.merge(dfGDP, on='City', how='left')\n\n# Делаем колонку населения\ndfPop = pd.Series(CityPop).reset_index()\ndfPop.columns = ['City', 'Population']\ndf = df.merge(dfPop, on='City', how='left')\n\n# Подсчитываем общее количество ресторанов в каждом городе\ndfUnRe = df.groupby('City')['Restaurant_id'].nunique().reset_index()\ndfUnRe.columns = ['City', 'Rest Count']\ndf = df.merge(dfUnRe, on='City', how='left')\n\n# Найдем относительные показатели GDP\ndf['GDR relativ'] = df['GDP'].apply(lambda x: x/(df['GDP'].max()))\n\n# Найдем относительные показатели населенности\ndf['Population relativ'] = df['Population'].apply(lambda x: x/(df['Population'].max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Найдем средние значения количества отзывов по городам\ndfNoR = df.groupby('City')['Number of Reviews'].mean().reset_index()\ndfNoR.columns = ['City', 'Review mean']\ndf = df.merge(dfNoR, on='City', how='left')\n\n# Теперь заполним недостающие значения в Number of Reviews\n#df['Number of Reviews'] = df['Number of Reviews'].fillna(df['Review mean']) - сперва заполнял средним по городам,\n# но, как оказалось, при заполнении недостающих занчений единицей, МАЕ снижается\ndf['Number of Reviews'] = df['Number of Reviews'].fillna(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"добавим еще несколько фитч:"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Чисто для прикола нашел в каких городах сколько есть мишленовских звезд у ресторанов. Вдруг, это может отражать\n# и общее качество ресторанов в городе?\nMichStars = {'Paris':118, 'Stockholm':0, 'London': 66, 'Berlin':16, 'Munich':13, 'Oporto': 0,\n       'Milan':15, 'Bratislava':0, 'Vienna':0, 'Rome':15, 'Barcelona':20, 'Madrid':15,\n       'Dublin':0, 'Brussels':21, 'Zurich':11, 'Warsaw':0, 'Budapest':0, 'Copenhagen':11,\n       'Amsterdam':11, 'Lyon':15, 'Hamburg':11, 'Lisbon':0, 'Prague':0, 'Oslo':0,\n       'Helsinki':0, 'Edinburgh':0, 'Geneva':0, 'Ljubljana':0, 'Athens':0,\n       'Luxembourg':16, 'Krakow':0}\n\ndfMS = pd.Series(MichStars).reset_index()\ndfMS.columns = ['City', 'Mich Stars']\ndf = df.merge(dfPrice, on='City', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Рэнкинг ресторана, относительно города, в котором этот ресторан расположен\ndf['Ranking mean'] = df['Ranking']/ df['Rest Count']\n\n# Сколько человек на 1 ресторан в городе\ndf['Men per Rest'] = df['Population'] / df['Rest Count']\n\n# Рэнкинг ресторана, относительно города и количества человек на ресторан\ndf['Ranking mean2'] = df['Ranking']/ (df['Rest Count']*df['Men per Rest'])\n\n# Посмотрим, сколько отзывов ресторана приходится на одного человека\ndf['Review relative'] = df['Number of Reviews'] / df['Men per Rest']\n\n# Найдем Ranking относительнос количества человек на ресторан\ndf['Ranking relative'] = df['Ranking']/df['Men per Rest']\n\n# Найдем цены, относительно GDP\ndf['Price relative'] = df['GDR relativ']*df['Price New']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Посмотрим, есть ли какие корреляции среди наших переменных. А то может зря я все выше налепил!)\n\nsns.set(font_scale=1)\nplt.subplots(figsize=(12, 12))\nsns.heatmap(df.corr(), square=True,\n              annot=True, fmt=\".1f\", linewidths=0.1, cmap=\"RdBu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Итак нам определенно не нужны следующие колонки: Ranking relative, Review relative, Rest Count, Population relativ,\n# GDR relativ, Price mean_x\n\ndf = df.drop(['Ranking relative','Review relative','Rest Count','Population relativ',\n         'GDR relativ', 'Price relative', 'Ranking mean2'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(font_scale=1)\nplt.subplots(figsize=(12, 12))\nsns.heatmap(df.corr(), square=True,\n              annot=True, fmt=\".1f\", linewidths=0.1, cmap=\"RdBu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создадим думисы для City\ndf = pd.get_dummies(df, columns=[ 'City',], dummy_na=True)\n\n# Создадим думисы для Price New\ndf = pd.get_dummies(df, columns=['Price New'], dummy_na=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# А вот с думмисами для Cuisine Style придется немножно посложнее\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmlb = MultiLabelBinarizer()\nDummCuisin = pd.DataFrame(mlb.fit_transform(df['Cuisine Style']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df,DummCuisin],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем колонки с данными типа object\nobject_columns = [s for s in df.columns if df[s].dtypes == 'object']\n\ndf.drop(object_columns, axis = 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Разбиваем датафрейм на части, необходимые для обучения и тестирования модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = df.query('sample == 1').drop(['sample'], axis=1)\ntest_data = df.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Заметим, что исходные рейтинги ресторанов округляются с шагом 0.5. Поэтому и предсказанные тоже округлим с шагом 0.5"},{"metadata":{"trusted":true},"cell_type":"code","source":"def round_custom(num):\n    return round(num / 0.5) * 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in predict_submission:\n    i=round_custom(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}