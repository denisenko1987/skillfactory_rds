{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Классификация изображений\n\n### Основная идея этого решения: взять предобученую на ImageNet сеть EfficientNet и дообучить под нашу задачу. \n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\n\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.models as Model\nfrom tensorflow.keras.layers import *\nimport tensorflow.keras.layers as layers\n\nfrom tensorflow.keras.applications.xception import Xception\n\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Работаем с Tensorflow v2**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Основные настройки"},{"metadata":{"trusted":true},"cell_type":"code","source":"# В setup выносим основные настройки: так удобнее их перебирать в дальнейшем.\n\nEPOCHS               = 10  # эпох на обучение\nBATCH_SIZE           = 16 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nLR                   = 1e-4\nVAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 224 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/'\nPATH = \"../working/car/\" # рабочая директория","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Устаналиваем конкретное значение random seed для воспроизводимости\nos.makedirs(PATH,exist_ok=True)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA / Анализ данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(y=train_df.Category.value_counts().values,\n           x=train_df.Category.value_counts().index,\n           color='r')\n# распределение классов достаточно равномерное - это хорошо","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Распаковываем картинки')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"../input/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Пример картинок (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index]))\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Посмотрим на примеры картинок и их размеры чтоб понимать как их лучше обработать и сжимать."},{"metadata":{"trusted":true},"cell_type":"code","source":"image = PIL.Image.open(PATH+'/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Подготовка данных"},{"metadata":{},"cell_type":"markdown","source":"## Аугментация данных\n#### **Впилим новый аугментатор данных**"},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install git+https://github.com/mjkvaak/ImageDataAugmentor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nAUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(240, 320)\n])\n\n# dataloaders\ntrain_datagen_2 = ImageDataAugmentor(\n        rescale=1./255,\n        augment=AUGMENTATIONS,\n        validation_split=VAL_SPLIT)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\n# data generators\ntrain_generator_2 = train_datagen_2.flow_from_directory(\n        PATH+'train/',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=True, \n        seed=RANDOM_SEED,\n        subset='training')\n\ntest_generator_2 = train_datagen_2.flow_from_directory(\n        PATH+'train/',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=True, seed=RANDOM_SEED,\n        subset='validation')\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Построение модели"},{"metadata":{},"cell_type":"markdown","source":"Протеституем, как будет работать предобученная сеть EfficientNetB4"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install efficientnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import efficientnet.tfkeras as efn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'efn' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c99e1f4af628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mefn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEfficientNetB6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'efn' is not defined"]}]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Замораживаем веса в базовой модели\nbase_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiating the model in the strategy scope creates the model on the TPU\n#with tpu_strategy.scope():\n# steps_per_execution=32\n\nmodel2 = Model.Sequential()\nmodel2.add(base_model)\n# model2.add(layers.Conv2D(32, 3, activation = 'relu', padding = 'same', \n#                         input_shape = input_shape))\n# model2.add(layers.BatchNormalization())\n\nmodel2.add(layers.GlobalAveragePooling2D())\nmodel2.add(layers.BatchNormalization()) \n#model2.add(layers.Dropout(0.25))\n   \nmodel2.add(layers.Dense(256, activation='relu'))\nmodel2.add(layers.Dropout(0.25))\n\n#model2.add(layers.BatchNormalization())\n#     model2.add(layers.Dropout(0.25))\n\nmodel2.add(layers.Dense(CLASS_NUM, activation='softmax'))\n\nmodel2.compile(loss=\"categorical_crossentropy\", \n               optimizer=optimizers.Adam(lr=LR), \n               metrics=[\"accuracy\"],\n               )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сколько слоев\nprint(len(model2.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сколько слоев обучилось\nprint(len(model2.trainable_variables))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Обучение модели"},{"metadata":{},"cell_type":"markdown","source":"Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ncheckpoint = ModelCheckpoint('best_model.hdf5', \n                             monitor = ['val_accuracy'], \n                             verbose = 1, \n                             mode = 'max')\n\nearlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n                                             patience=3, \n                                             restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.25,\n                              patience=2, min_lr=0.0000001, verbose=1,\n                             mode='auto')\n\ncallbacks_list = [checkpoint,earlystop,reduce_lr] # lrscheduler,lr_callback","execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'ModelCheckpoint' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-64599ae70245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m checkpoint = ModelCheckpoint('best_model.hdf5', \n\u001b[0m\u001b[1;32m      2\u001b[0m                              \u001b[0mmonitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              mode = 'max')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'ModelCheckpoint' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"# Обучаем. Этап 1:"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model2.fit(\n        train_generator_2,\n        steps_per_epoch = train_generator_2.samples//train_generator_2.batch_size,\n        validation_data = test_generator_2, \n        validation_steps = test_generator_2.samples//test_generator_2.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\nmodel2.save('../working/model_last.hdf5')\nmodel2.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"scores = model2.evaluate_generator(test_generator_2, steps=len(test_generator_2), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round(model2.optimizer.lr.numpy(), 5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Обучение. Этап 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# начинаем постепенную разморозку слоев для базовой модели для обучения\nbase_model.trainable = True\n\n# Fine-tune from this layer onwards\nfine_tune_at = len(base_model.layers)//2 # количество слоев, которые будут обучаться\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel2.compile(loss=\"categorical_crossentropy\", \n               optimizer=optimizers.Adam(lr=LR), \n               metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model2.fit(\n        train_generator_2,\n        steps_per_epoch = train_generator_2.samples//train_generator_2.batch_size,\n        validation_data = test_generator_2, \n        validation_steps = test_generator_2.samples//test_generator_2.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model2.evaluate_generator(test_generator_2, steps=len(test_generator_2), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Обучение. Этап 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # начинаем постепенную разморозку слоев для базовой модели для обучения\n# base_model.trainable = True\n\n# # Fine-tune from this layer onwards\n# fine_tune_at = len(base_model.layers)//2 # количество слоев, которые будут обучаться\n# fine_tune_at = int(fine_tune_at*1.5)\n\n# # Freeze all the layers before the `fine_tune_at` layer\n# for layer in base_model.layers[:fine_tune_at]:\n#   layer.trainable =  False\n\n# LR= 1e-5\n# model2.compile(loss=\"categorical_crossentropy\", \n#                optimizer=optimizers.Adam(lr=LR), \n#                metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = model2.fit(\n#         train_generator_2,\n#         steps_per_epoch = len(train_generator_2),\n#         validation_data = test_generator_2, \n#         validation_steps = len(test_generator_2),\n#         epochs = EPOCHS,\n#         callbacks = callbacks_list\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scores = model2.evaluate_generator(test_generator_2, steps=len(test_generator_2), verbose=1)\n# print(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# acc = history.history['accuracy']\n# val_acc = history.history['val_accuracy']\n# loss = history.history['loss']\n# val_loss = history.history['val_loss']\n \n# epochs = range(len(acc))\n \n# plt.plot(epochs, acc, 'b', label='Training acc')\n# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n# plt.title('Training and validation accuracy')\n# plt.legend()\n \n# plt.figure()\n \n# plt.plot(epochs, loss, 'b', label='Training loss')\n# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n# plt.title('Training and validation loss')\n# plt.legend()\n \n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Пока пропускаем этап 3, так как особой пользы он не приносит."},{"metadata":{},"cell_type":"markdown","source":"# Обучение. Этап 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\n\nLR = 1e-5\nmodel2.compile(loss=\"categorical_crossentropy\", \n               optimizer=optimizers.Adam(lr=LR), \n               metrics=[\"accuracy\"])\n\nhistory = model2.fit(\n        train_generator_2,\n        steps_per_epoch = train_generator_2.samples//train_generator_2.batch_size,\n        validation_data = test_generator_2, \n        validation_steps = test_generator_2.samples//test_generator_2.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model2.evaluate_generator(test_generator_2, steps=len(test_generator_2), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Обучение. Этап 5. Корректировка настроек"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS               = 6\nBATCH_SIZE           = 4 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nLR                   = 1e-5\n\nIMG_SIZE             = 512 # увеличиваем размер картинки\nIMG_CHANNELS         = 3\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n\n])\n\n# dataloaders\ntrain_datagen_2 = ImageDataAugmentor(\n        rescale=1./255,\n        augment=AUGMENTATIONS,\n        validation_split=VAL_SPLIT)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data generators\ntrain_generator_2 = train_datagen_2.flow_from_directory(\n        PATH+'train/',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=True, \n        seed=RANDOM_SEED,\n        subset='training')\n\ntest_generator_2 = train_datagen_2.flow_from_directory(\n        PATH+'train/',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=True, \n        seed=RANDOM_SEED,\n        subset='validation')\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# загружаем базовую модель\n\nbase_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)\n\n# # Устанавливаем новую \"голову\" (head)\n\nmodel2 = Model.Sequential()\nmodel2.add(base_model)\n# model2.add(layers.Conv2D(32, 3, activation = 'relu', padding = 'same', \n#                         input_shape = input_shape))\n# model2.add(layers.BatchNormalization())\n\nmodel2.add(layers.GlobalAveragePooling2D())\nmodel2.add(layers.BatchNormalization())\n#model2.add(layers.Dropout(0.25))    \n\nmodel2.add(layers.Dense(256, activation='relu'))\nmodel2.add(layers.Dropout(0.25))\n#model2.add(layers.BatchNormalization())\n#     model2.add(layers.Dropout(0.25))\n\nmodel2.add(layers.Dense(CLASS_NUM, activation='softmax'))\n\nmodel2.compile(loss=\"categorical_crossentropy\", \n               optimizer=optimizers.Adam(lr=LR), \n               metrics=[\"accuracy\"],\n               )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Загружаем веса уже обученной модели\nmodel2.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3,\n                              patience=2, min_lr=0.0000001, verbose=1,\n                             mode='auto')\n\ncallbacks_list = [checkpoint,earlystop,reduce_lr]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nhistory = model2.fit(\n        train_generator_2,\n        steps_per_epoch = train_generator_2.samples//train_generator_2.batch_size,\n        validation_data = test_generator_2, \n        validation_steps = test_generator_2.samples//test_generator_2.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model2.evaluate_generator(test_generator_2, steps=len(test_generator_2), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Предсказание на тестовых данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator.samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model2.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator_2.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv(PATH+'submission.csv', index=False)\nprint('Save submit')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TTA"},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nAUGMENTATIONS = albumentations.Compose([\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.Rotate(limit=30, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),\n    albumentations.OneOf([\n        albumentations.CenterCrop(height=224, width=200),\n        albumentations.CenterCrop(height=200, width=224),\n    ],p=0.5),\n    albumentations.OneOf([\n        albumentations.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    albumentations.GaussianBlur(p=0.05),\n    albumentations.HueSaturationValue(p=0.5),\n    albumentations.RGBShift(p=0.5),\n    albumentations.FancyPCA(alpha=0.1, always_apply=False, p=0.5),\n    albumentations.Resize(IMG_SIZE, IMG_SIZE)\n])\n\n# dataloaders\ntest_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment=AUGMENTATIONS,\n        validation_split=VAL_SPLIT)\n\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tta_steps = 10\npredictions = []\n\nfor i in range(tta_steps):\n    preds = model2.predict_generator(test_sub_generator, verbose=1) \n    predictions.append(preds)\n\npred = np.mean(predictions, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.argmax(pred, axis=-1) #multiple categories\nlabel_map = (train_generator_2.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]\n\nfilenames_with_dir=test_sub_generator.filenames\nTTA_submission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nTTA_submission['Id'] = TTA_submission['Id'].replace('test_upload/','')\nTTA_submission.to_csv('TTA_submission.csv', index=False)\nprint('Save submit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TTA_submission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Clean PATH\n# import shutil\n# shutil.rmtree(PATH)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}